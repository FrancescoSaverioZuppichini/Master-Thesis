{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from models import *\n",
    "from utils import get_learner, get_probs_and_labels_from_preds, get_patches_form_df\n",
    "from callbacks import StoreBestWorstAndSample, ROC_AUC\n",
    "from os import path\n",
    "from datasets.TraversabilityDataset import TraversabilityDataset, get_transform\n",
    "from Config import Config\n",
    "from patches import *\n",
    "\n",
    "class StorePredictions():\n",
    "    def __init__(self, model_name, model_dir, store_dir):\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = model_dir\n",
    "        self.dfs = []\n",
    "        self.df_path2df = {}\n",
    "        self.store_dir = store_dir\n",
    "\n",
    "    def handle_dataset(self, dataset):\n",
    "        df = dataset.df\n",
    "        learner, _ = get_learner(self.model_name, self.model_dir, callbacks=[], dataset=dataset)\n",
    "        preds = learner.get_preds(learner.data.test_dl)\n",
    "        probs, labels = get_probs_and_labels_from_preds(preds)\n",
    "\n",
    "        df['out_0'] = probs[:, 0]\n",
    "        df['out_1'] = probs[:, 1]\n",
    "        df['prediction'] = labels.cpu().tolist()\n",
    "\n",
    "        return df\n",
    "\n",
    "    def store(self):\n",
    "        for df_path, df in tqdm.tqdm(self.df_path2df.items()):\n",
    "            file_name = path.basename(df_path)\n",
    "            map_name = path.basename(path.split(df_path)[0])\n",
    "            out_path = path.normpath('{}/{}/'.format(self.store_dir, map_name))\n",
    "            os.makedirs(out_path, exist_ok=True)\n",
    "            out_path = path.normpath('{}/{}'.format(out_path, file_name))\n",
    "            df.to_csv(out_path)\n",
    "\n",
    "    def restore(self):\n",
    "        dfs_path = glob.glob(self.store_dir + '/**/*.csv')\n",
    "\n",
    "        for df_path in tqdm.tqdm(dfs_path):\n",
    "            df = pd.read_csv(df_path)\n",
    "            self.df_path2df[df_path] = df\n",
    "            self.dfs.append(df)\n",
    "\n",
    "    def __call__(self, datasets):\n",
    "        bar = tqdm.tqdm(datasets)\n",
    "        for dataset in bar:\n",
    "            if type(dataset) is not TraversabilityDataset: raise ValueError('inputs must be of type TraversabilityDataset')\n",
    "            bar.set_description('[INFO] Reading {}'.format(dataset.df_path))\n",
    "            if len(dataset) > 0:\n",
    "                df = self.handle_dataset(dataset)\n",
    "                self.dfs.append(df)\n",
    "                self.df_path2df[dataset.df_path] = self.dfs[-1]\n",
    "\n",
    "        return self.dfs\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "[INFO] Reading /media/francesco/saetta/no-shift-88-750/train//df/bars1/1550614988.2771952-patch.csv: 100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "concat = TraversabilityDataset.from_paths(Config.DATA_ROOT, [Config.DATA_DIR], tr=0.45, transform=get_transform(scale=10))\n",
    "store = StorePredictions(Config.BEST_MODEL_NAME, Config.BEST_MODEL_DIR, '/home/francesco/Desktop/store-test/')\n",
    "dfs = store(concat.datasets)\n",
    "# store.restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Best():\n",
    "    name = 'best'\n",
    "    def __call__(self, df):\n",
    "        df = df.loc[df['label'] == 1]\n",
    "        return df.sort_values(['out_1'], ascending=False)\n",
    "\n",
    "class Worst():\n",
    "    name = 'worst'\n",
    "    def __call__(self, df):\n",
    "        df = df.loc[df['label'] == 0]\n",
    "        return df.sort_values(['out_0'], ascending=False)\n",
    "\n",
    "class FalseNegative():\n",
    "    name = 'false_negative'\n",
    "    def __call__(self, df):\n",
    "        return false_something(df, 0)\n",
    "\n",
    "class FalsePositive():\n",
    "    name = 'false_positive'\n",
    "    def __call__(self, df):\n",
    "        return false_something(df, 1)\n",
    "\n",
    "\n",
    "def false_something(df, something):\n",
    "    neg = df.loc[df['label'] == something]\n",
    "    return neg.loc[neg['prediction'] != something]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterPatches():\n",
    "    def __init__(self, transform=None):\n",
    "        self.df = None\n",
    "        self.transform = transform\n",
    "    \n",
    "    def transform_patches(self, patches):\n",
    "        \n",
    "        return [self.transform(patch) for patch in patches]\n",
    "    \n",
    "    def filter_patches(self, df, image_dir):\n",
    "        return self.transform_patches(get_patches_form_df(df, image_dir))\n",
    "\n",
    "    def __call__(self, df, image_dir, filter_fn, n=10):\n",
    "        filtered_df = filter_fn(df)\n",
    "        filtered_df = filtered_df.head(n)\n",
    "        return filtered_df, self.filter_patches(filtered_df, image_dir),\n",
    "\n",
    "class Convert2Patches():\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        df, patches = data\n",
    "        \n",
    "        return (df, [Patch.from_tensor(patch) for patch in patches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_interesting_patches(transform, df, image_dir):\n",
    "    filters = [Best(), Worst(), FalseNegative(), FalsePositive()]\n",
    "    result = {}\n",
    "    \n",
    "    f_patch = FilterPatches(transform=transform)\n",
    "    c_patch = Convert2Patches()\n",
    "    \n",
    "    for f in filters:\n",
    "        result[f.name] = c_patch(f_patch(df, image_dir, f))\n",
    "        \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_all_interesting_patches(get_transform(scale=1), store.dfs[0], Config.DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, patches = data['false_negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for (idx, row), patch in zip(df.iterrows(), patches):\n",
    "    patch.plot2d()\n",
    "    plt.title('advancement={:.2f} prediction = {} ground truth = {}'.format(row['advancement'], row['prediction'], row['label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patches[0].plot2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Patch.from_tensor(patches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = cv2.imread('/home/francesco/Documents/Master-Thesis/core/maps/test/querry-big-10.png')\n",
    "hm = cv2.cvtColor(hm, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot_box_on_hm(row, hm, patch_size):\n",
    "        fig = plt.figure()\n",
    "        ax = plt.gca()\n",
    "        x, y, ang, ad = row[\"hm_x\"], \\\n",
    "                        row[\"hm_y\"], \\\n",
    "                        row[\"pose__pose_e_orientation_z\"], \\\n",
    "                        row[\"advancement\"]\n",
    "\n",
    "        sns.heatmap(hm / 255, vmin=0, vmax=1, ax=ax)\n",
    "\n",
    "        rect = mpatches.Rectangle((x - patch_size // 2, y - patch_size // 2), patch_size,\n",
    "                                  patch_size, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box_on_hm(df.iloc[10], hm, 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p.plot2d()\n",
    "plt.title(df.iloc[10]['advancement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.plot3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
