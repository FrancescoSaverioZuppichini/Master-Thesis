\documentclass[../document.tex]{subfiles}
\begin{document}
\begin{abstract}
    Effective identification of traversable terrain is essential to operate mobile robots in different environments. 
    Historically, to estimate traversability, texture and geometric features were extracted before train a traversability estimator in a supervised way. However, with the recent deep learning breakthroughs in computer vision, terrain features may be learned directly from raw data, images or heightmaps, with higher accuracy.
    
    We implement a full pipeline to estimate traversability with high accuracy using only data generated through simulation using a deep convolutional neural network. The method is based on the framework proposed by Chavez-Garcia et al. \cite{omar2018traversability} and was originally tested on two wheels small robot. Collecting data in a simulation enviroment yields several advantanges over real world. Ground can be easily generated to include any features and can be loaded on the fly into the simulator. Multiple simulations can be run in parallel reducing the cost for real world hardware.

    The dataset wasgenerated using thirty synthetic synthetic surfaces with different features such as slopes, holes, bumps, and walls. Then, we let the robot walk each map on for a certain amount of time while storing its interactions. Later, precisely crop a patch from each simulation trajectory's point that includes the whole robot's footprint and the amount of ground it should reach without obstacles in a decided time window. Then, we label each patch as traversable or not traversable based on a minimum advancement depending on the robot used. We open source the framework and the same methodology can be used with any type or robots. We test the methodology on a legged crocodile-like robot that presents challenging locomotion to be learned in order to correctly predict its traceability.
    
    We select and test different networks architecture and select the best performing one. We quantity shows its performance with different numeric metrics on different real-world terrains. In addition, we qualitative evaluate the network by showing the predicted traversability probability on different grounds to better visualize the acquired knowledge.  
    
    Later, we utilize model interpretability techniques to understand which patches confuse the network. We visualize the ground regions that the network fails to classify and find which part of the inputs was responsible for the wrong predictions. Finally, we test the model strength and robustness by comparing its prediction on custom patches composed by crafted features, such as a patch with a wall ahead, to the ground truth obtained by running again Krock on that ground in the simulator. The results suggest that the model was able to match the groun truth in different situations.


\end{abstract}
\end{document}
% \cite{einstein} 
