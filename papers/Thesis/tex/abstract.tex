\documentclass[../document.tex]{subfiles}
\begin{document}
\begin{abstract}
    All living beings, including humans, need to travel to eat, sleep and breed. To properly move into a new ground its traversability must be estimated. Thanks to millennia of evolutions this task has been effectively solved by mother nature. Every species has learned to use their local sensors to effectively navigate new environments. Humans, for instance, are equipped with a powerful traversability estimator, called vision, that is able to classify grounds by extract features from a local region, a patch, such as elevation, size, and steepness and combined them with the brain to produce a local planner able to find a suboptimal path to cross.

    Similarly, ground robots need to walk in order to fulfill their tasks. Taking inspiration from nature, robots must be able to correctly aggregate terrain features to predict their traversability. Two main approaches have emerged over the years to collect the data, geometric and appearance. The first utilized purely geometric features to label a patch, while the second relies mostly on camera's images. In both cases, those samples are used in supervised learning to train a traversability estimator. While appearance data must be collected directly from a real or simulated environment, geometric features do not depend on the robot's interactions with the ground. However, with the recent deep learning breakthroughs in computer vision, the two methods may overlap. For instance, geometric features may be learned directly from raw data, images or heightmaps. 
    
    We trained a deep convolutional neural network on data to gather entirely through simulation to predict traversability for a legged crocodile-like robot called Krock. The training data was generated by letting the robot walking for a certain amount of time on thirty synthetic maps with different grounds features such as slopes, holes, bumps, and walls in a simulator environment while storing his pose, position, and orientation. We later use that information to precisely crop a patch for simulation trajectory's point. This small portion of ground includes the whole robot's footprint and the ground it would reach using its maximum speed on flat ground. Each patch is label traversable if Krock's advancement in that point, computed using a time window of two seconds, is major than a threshold of twenty centimeters, not traversable otherwise. 
    
    After fitting the model, we quantity shows its performance with different numeric metrics on different real-world terrains. Then, we qualitative evaluate the network by showing the predicted traversability probability on those grounds. 
    
    Later, we utilize model interpretability techniques to understand which patches confuse the most the network. We visualized the ground regions that the network fails to classify and visualize which part of the inputs was responsible for the wrong predictions.
    
    Finally, we test the model strength and robustness by comparing its prediction on custom patches composed by crafted features, such as a patch with a wall ahead, to the ground truth obtained by run again Krock on that ground in the simulator. 

\end{abstract}

% \cite{einstein} 

\end{document}
