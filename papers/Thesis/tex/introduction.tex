\documentclass[../document.tex]{subfiles}
\begin{document}
\chapter{Introduction}

All living beings, including humans, need to traverse ground to eat, sleep and breed. Animals through millennia of evolution have developed different techniques to classify ground regions. Usually, local sensors are used to map new terrain to effectively navigate the environment. Humans, for instance, are equipped with a powerful traversability estimator, called vision, that is able to extract features from a local region, a patch, such as elevation, size, and steepness and combine them with the brain to produce a local planner able to find a suboptimal path to cross.

Similarly, ground robots need to walk in order to fulfill their tasks. Taking inspiration from nature, robots must be able to correctly aggregate terrain features to predict their traversability. In this project, we consider the task to estimate the traversability of 3D terrain for a specific ground robot. Traversability can be estimated by 3D geometric, appearance features or both \cite{papadakis}. The first one utilizes purely geometric features to label a patch, while the second relies on categories, glass, rocks, etc, with different traversability probabilities extract mostly on camera's images. In both cases, those samples are used in supervised learning to train a traversability estimator. While appearance data must be collected directly from a real or simulated environment, geometric features do not directly depend on the robot's interactions with the ground. 

In most indoor scenarios, data is collected through specific hardware, such as infrared sensors, cameras or LIDAR, during a robot exploration of the environment. Due to their artificial design, indoor environments shared similar features across the world, the flatness of the floor, stairs, and ceil. So, even if an agent is trained with samples collected in one location, due to physical limitations, the learned mapping can be effective in different locations. Moreover, in indoor environments, traversability estimation is mostly solved with obstacle avoidance since, by design, the floor alone do not include bumps, ramps or holes. In addition, while the robot operates there may be other agents interacting with the environment, such as humans, therefore a correct function to avoid collision must properly learn to effective move safely the robot.

On the other hand, outdoor grounds may have less artificial obstacle but they have a not homogeneous ground making challenging to estimate where the robot can properly travel. Also, a given patch with a specific shape may not be traversable by all direction due to the not uniform features of the terrain. On top of that, using real-world data may be unfeasible due to the time required to move the robot on different grounds and the possibility to introduce bias if the data samples are not varied enough. Fortunately, the ground can be generated artificially and used in a simulated environment to let the robot walk in it while storing its interactions. Moreover, grounds maps can be easily obtained nowadays by using third-party services such as google maps or flying drone equipped with mapping technologies.

We proposed a full pipeline to estimate traversability tested on a legged crocodile-like robot on uneven terrain based entirely on data gathered through simulation. Simulation offers several advantages than real-world data collection. First, we can include a rich array of different terrains without the need to physically move them. Data is collected faster and multiple simulations can be launch in parallel keeping the cost of the real world hardware low. We first generated thirty synthetic maps encoded as heightmaps with different features: bumps, walls, slopes, steps, and holes. Then, we run the robot on each one of them for a certain amount of time while storing its interactions with the environment, position, and orientation. Later, we generate a training dataset by cropping a patch for each stored data point in such way that includes the robot's footprint and the maximum possible amount of ground that can traverse in a selected time window. After, we label each patch by traversable or not traversable if the robot's advancement computed in that time using the same time window is less or greater than a threshold. The threshold depends on the robot's locomotion and is calculated by spawning it in front of the different obstacle and observing its advancement, we set the value for the tested robot to twenty centimeters. Those patches are used to fit a deep convolutional neural network to prediction the traversability leaving to the network the task to extract important ground's features.

The report is organized as follow, the next chapter \ref{chap: related-work} introduces the related work, chapter \ref{chap: methodology} gives a high-level overview of our approach, chapter \ref{chap: implementation} talks in deep about the implementation details showing the dataset generation procedure and describes different convolutional neural network architectures. Chapter \ref{chap: results} describes the model selection process, shows the quantitively and qualitatively results for the best performing architecture. Chapter \ref{chap: interpretability}, we test the model's predictions robustness using different techniques. First, we proved the network's ability to learn meaningful features from the inputs, section \ref{sec:  features-separability}. Then, \ref{sec: quarry-dataset} we visualize different inputs to understand which grounds' regions caused the predictions.  We adopted a technique that allows highlighting the part of the terrain contributes the most to the network's output. Lastly, in section \ref{sec: robustness}, we tested the model's robustness by creating different patches with unique characteristics. We compared the estimator's predictions to the ground truth gather the simulator.
\end{document}