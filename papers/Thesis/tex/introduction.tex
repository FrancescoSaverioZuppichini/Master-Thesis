\documentclass[../document.tex]{subfiles}
\begin{document}
\chapter{Introduction}

All living beings, including humans, need to traverse ground to eat, sleep and breed. Animals through millennia of evolution have developed different techniques to classify ground regions. Usually, local sensors are used to map new terrain to effectively navigate the environment. Humans, for instance, are equipped with a powerful traversability estimator, called vision,  able to extract features from a local region, a patch, such as elevation, size and steepness and combine them to produce a local planner able to find a suboptimal path to cross.

Similarly, ground robots need to walk in order to fulfill their tasks. Taking inspiration from nature, robots must be able to correctly aggregate terrain features to predict their traversability. In this project, we consider the task to estimate the traversability of 3D terrain for a specific ground robot. Traversability can be estimated by 3D geometric, appearance features or both \cite{papadakis}. The first one utilizes purely geometric features to label a patch, while the second relies on categories, glass, rocks, etc, with different traversability probabilities extract mostly on camera's images. While appearance data must be collected directly from a real or simulated environment, geometric features do not directly depend on the robot's interactions with the ground. In both cases, these samples are used in supervised learning to train a traversability estimator.

In most indoor scenarios, data is collected through local sensors during a robot exploration of the environment. Thanks to their artificial design, indoor environments share similar features across the world, the flatness of the floor, stairs, and ceil. So, even if an agent is trained with samples collected in one location, due to physical limitations, the learned mapping can be still effective in different locations. Moreover, in indoor environments, traversability estimation is mostly solved with obstacle avoidance since, by design, the floor alone do not include bumps, ramps or holes. In addition, while the robot operates there may be other agents interacting with the environment, such as humans, therefore a correct function to avoid collision must properly learn to effectively move safely the robot.

On the other hand, outdoor terrains may have less artificial obstacles but they don't have a homogeneous ground making more challenging to estimate where the robot can properly travel. Also, a given patch with a specific shape may not be traversable in all direction due to the non uniform features of the surfaces. On top of that, using real-world data may be unfeasible due to the time required to move the robot on different grounds and the possibility to introduce bias if the data samples are not varied enough. Fortunately, the ground can be generated artificially and used in a simulated environment to let the robot walk in it while storing its interactions. Moreover, grounds maps can be easily obtained by using third-party services such as google maps or flying drones equipped with mapping technologies.

We propose a full pipeline to estimate traversability tested on a legged crocodile-like robot on uneven terrain based entirely on data gathered through simulation. Data collection through simulation offers several advantages such as cost, quality and time. We generate thirty synthetic maps encoded as heightmaps with different features: bumps, walls, slopes, steps, and holes. Then, we run the robot on each one of them for a certain amount of time while storing its position and orientation and its interactions with the environment. Later, we generate a training dataset by cropping a patch for each trajectory in a way that includes the robot's footprint and the maximum possible amount of ground that can be traversed in a selected time window. We label each patch using a threshold that depends on the robot's locomotion. These patches are used to fit a deep convolutional neural network to prediction the traversability.


This thesis is organized as follow, the in chapter \ref{chap: related-work} introduces the related work. In chapter \ref{chap: methodology} gives a high-level overview of our approach. Chapter \ref{chap: implementation} carefully explains the implementation details showing the dataset generation procedure and describes different convolutional neural network architectures. Chapter \ref{chap: results} discuss the model selection process, showing both quantitively and qualitatively results for the best performing architecture. In chapter \ref{chap: interpretability} we evaluate the model's robustness using different techniques. We prove the network's ability to learn meaningful features from the inputs, section \ref{sec:  features-separability}. Then, \ref{sec: quarry-dataset} we visualize different inputs to understand which grounds' regions caused the wrong predictions. Lastly, in section \ref{sec: robustness}, we test the model's robustness by creating different patches with unique characteristics. We compared the estimator's predictions to the ground truth gather the simulator. In Chapter \ref{chap : conclusions} we draw the conclusion, marking some limitations of the method and describing how to tackl them.
\end{document}